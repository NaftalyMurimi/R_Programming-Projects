library("seqinr")
sars <- read.fasta(file = 'sarscov2.fasta')
da= "C:/Users/nafmu/Desktop/Cognitive Tech/R/Lecture 4 R for text-mining-20241203/sarscov2.fasta"
sars <- read.fasta(file = da)
sars
View(sars)
length(sars[[1]])
table(sars[[1]])
head(sars[[1]])
tail(sars[[1]])
count(sars[[1]], 2)
count(sars[[1]], 3)
load("genbank.RData") # loading the data
head(genbank, 20)
# Regular expressions -------------------------------------------------------------
g= "C:/Users/nafmu/Desktop/Cognitive Tech/R/Lecture 4 R for text-mining-20241203/genbank.RData"
load(g) # loading the data
head(genbank, 20)
head(genbank, 20)
gb <- paste(genbank, collapse = "\n")
gb
accPos <- regexec("ACCESSION\\s+(\\S{6})", gb)
accPos
# "ACCESSION", one or more white spaces, and 6 non-white spaces
accession <- regmatches(gb, accPos)
accession
defPos <- regexec("DEFINITION\\s+((\\S| )+\\.)", gb)
# "DEFINITION", one or more white spaces, one or more non-white spaces or space, a dot.
definition <- regmatches(gb, defPos)
definition
defPos <- regexec("ORGANISM\\s+((\\S| )+)", gb)
defPos
defPos
defPos
defPos <- regexec("ORGANISM\\s+((\\S| )+)", gb)
# "ORGANISM", one or more white spaces, one or more non-white spaces or space.
organism <- regmatches(gb, defPos)
organism
seqPos <- gregexpr("ORIGIN.+$",gb)  # "ORIGIN", one or more any characters, end of a line.
sequence <- regmatches(gb, seqPos)
sequence
rm(list = ls()) # cleaning the workspace
## Statistical testing ====================================================
library(ISLR)
data(Auto)
attach(Auto)
sAuto <- subset(Auto, cylinders >=6)
# t-test
tt <- t.test(horsepower~cylinders, data=sAuto)
sAuto
# t-test
tt <- t.test(horsepower~cylinders, data=sAuto)
tt$statistic
tt$p.value # There is a significant difference in horsepower between cars with 6 and 8 cylinders
tt <- t.test(cylinders~horsepower, data=sAuto)
boxplot(horsepower~cylinders,data=sAuto)
sAuto <- subset(Auto, cylinders)
# t-test
tt <- t.test(horsepower~cylinders, data=sAuto)
#tt <- t.test(cylinders~horsepower, data=sAuto)
tt$statistic
tt$p.value # There is a significant difference in horsepower between cars with 6 and 8 cylinders
boxplot(horsepower~cylinders,data=sAuto)
boxplot(horsepower~cylinders,data=sAuto)
# Task 2
# Load the tweets.RData file into RStudio. It is a data frame containing the tweets published
# by the RDataMining profile in a certain time range
load("tweets.RData")
tweets
summary(tweets)
# b) Change "-" to “/” in the publication dates.
str(tweets)
x <- c("ablc", "bcd", "cde", "bbbbdefc")
# Replace first match
sub("bc", "kk", x)
# Output: [1] "agh" "ghd" "cde" "def"
# Replace all matches
gsub("bc", "ko", x)
x <- c("ablc", "bcd", "bcde", "bbbbdefc")
# Replace first match
sub("bc", "kk", x)
x <- c("ablc", "bcd", "bcdebc", "bbbbdefc")
# Replace first match
sub("bc", "kk", x)
# Output: [1] "agh" "ghd" "cde" "def"
# Replace all matches
gsub("bc", "ko", x)
tweets
tweets$created <- gsub("-", "/", tweets$created) # musi być na zmienna adresująca kolumne w df, żeby ją nadpisać
head(tweets)
tweets$created <- substr("/", ".", tweets$created)
tweets$created <- substr("-", ".", tweets$created)
tweets$created <- substr("-", "/", tweets$created) # musi być na zmienna adresująca kolumne w df, żeby ją nadpisać
head(tweets)
tweets$created <- substr("-", "/", tweets$created) # musi być na zmienna adresująca kolumne w df, żeby ją nadpisać
tweets
tweets$created <- gsub("-", "/", tweets$created) # musi być na zmienna adresująca kolumne w df, żeby ją nadpisać
head(tweets)
# Task 2
# Load the tweets.RData file into RStudio. It is a data frame containing the tweets published
# by the RDataMining profile in a certain time range
load("tweets.RData")
# a) What is the number of tweets?
nrow(tweets)
summary(tweets)
# b) Change "-" to “/” in the publication dates.
str(tweets)
tweets$created <- gsub("-", "/", tweets$created) # musi być na zmienna adresująca kolumne w df, żeby ją nadpisać
head(tweets)
# c) Create a new column containing only the year of publication.
tweets$year <- gsub("^(\\d{4}).*", "\\1", tweets$created)
head(tweets)
# c) Create a new column containing only the year of publication.
tweets$year <- gsub("^(\\d{4}).*", tweets$created)
# Output: [1] "agh" "ghd" "cde" "def"
# Replace all matches
gsub("bc", "ko", x)
# Create a violin plot of retweet counts per year. Mark years with different colours
# (parameter fill).
library(ggplot2)
violin_plot <- ggplot(tweets, aes(x = year, y = retweetCount, fill = year)) +
geom_violin()
violin_plot
# e) Check how many words there are in each tweet. Hint: if you have a list, in which
# each element is a vector of words used in a tweet, you may use the lengths()
# function.
words <- unlist(strsplit(tweets$text, "\\s+"))
words
length(words) # However here I get how many words are in all tweets not in individual tweets
word_counts <- lengths(strsplit(tweets$text, "\\s+")) # correct approach
word_counts
# a) What is the number of tweets?
nrow(tweets)
# g) Make a wordcloud plot with words that appeared at least 10 times.
library(wordcloud)
my_table <- table(words)
sub_words <- subset(x = my_table, my_table >= 10)
# x - dane, których chcę użyć
# subset - subset konkretnie mniejszy lub równy 10
sub_words
# tworzenie chmury
cloud <- wordcloud(
names(sub_words), # przekazuje słowa do chmury
freq = sub_words, # przekazuje częstotliwość tych słów do chmury
random.order = F, # zapewnia porządek malejący wg częstotliwości
colors = brewer.pal(8, "Dark2"), # Dodanie kolorów z palety
scale = c(4, 0.5) # Dopasowanie skali i rozmiaru słów
)
# tworzenie chmury
cloud <- wordcloud(
names(sub_words), # przekazuje słowa do chmury
freq = sub_words, # przekazuje częstotliwość tych słów do chmury
random.order = F, # zapewnia porządek malejący wg częstotliwości
colors = brewer.pal(8, "Dark2"), # Dodanie kolorów z palety
scale = c(8, 0.5) # Dopasowanie skali i rozmiaru słów
)
# tworzenie chmury
cloud <- wordcloud(
names(sub_words), # przekazuje słowa do chmury
freq = sub_words, # przekazuje częstotliwość tych słów do chmury
random.order = F, # zapewnia porządek malejący wg częstotliwości
colors = brewer.pal(8, "Dark2"), # Dodanie kolorów z palety
scale = c(2, 0.5) # Dopasowanie skali i rozmiaru słów
)
# tworzenie chmury
cloud <- wordcloud(
names(sub_words), # przekazuje słowa do chmury
freq = sub_words, # przekazuje częstotliwość tych słów do chmury
random.order = F, # zapewnia porządek malejący wg częstotliwości
colors = brewer.pal(8, "Dark2"), # Dodanie kolorów z palety
scale = c(1, 0.5) # Dopasowanie skali i rozmiaru słów
)
head(freq_table)
# text cleaning (optional, I guess, there should be more done, like removing URLs but don't know how to do that lol)
# to clear the text I can convert everything into lowercase and remove punctuation
words <- tolower(words)
words <- gsub("[[:punct:]]", "", words) # it says: remove punctuation and paste nothing in its place
freq_table <- sort(table(words), decreasing=T)
head(freq_table)
tail(freq_table)
