lapply(list_data, mean)
j<-c(c(2:8), c(5:12))
j
lapply(j, min)
j<-list(c(2:8), c(5:12))
j
lapply(j, min)
sapply(m,2, sum)
sapply(m, sum)
lapply(j, min)
sapply(j, min)
data <- c(1, 2, 3, 4, 5, 6)
groups <- factor(c("A", "A", "B", "B", "C", "C"))
tapply(data, groups, sum)
mapply(sum, 1:5, 1:5, 1:5)
lapply(j, min)
# tapply
x <- 1:20
x
y <- factor(rep(letters[1:5], each = 4))
y
tapply(x, y, sum)
# by
data("iris")
attach(iris)
head(iris)
by(iris, list(Species=iris$Species), function(x){
y <- subset(x, select= -Species)
apply(y, 2, mean)
} )
# aggregate
iris.x <- subset(iris, select= -Species)
iris.x
iris.s
iris.s <- subset(iris, select= Species)
iris.s
aggregate(iris.x, iris.s, mean)
# Sorting
sort(iris$Sepal.Length) #vector
# Sorting a data frame the hard way
sIris <- sort(iris$Sepal.Length, index.return=TRUE)
head(iris[sIris$ix,]) #sorted data frame
plot(g)
g <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
library(ggplot2)
library(ggplot2)
library(ggplot2)
library(ggplot2)
library(ggplot2)
# Load package with data
library(ISLR)
data(Auto)
attach(Auto)
head(Auto)
# Initialize a ggplot
g <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
plot(g)
g + scale_x_reverse()
# Zoom in on plot
g1 <- g + coord_cartesian(xlim=c(10,25),ylim=c(10,40))
g <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
g <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
plot(g)
# Initialize a ggplot
g <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point() +
geom_smooth(method="lm")
plot(g)
# Zoom in on plot
g1 <- g + coord_cartesian(xlim=c(10,25),ylim=c(10,40))
plot(g1)
plot(g)
plot(g1)
# Zoom in on plot
g1 <- g + coord_cartesian(xlim=c(10,20),ylim=c(10,40))
plot(g1)
# Initialize a ggplot
g <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
plot(g)
# Zoom in on plot
g1 <- g + coord_cartesian(xlim=c(10,20),ylim=c(10,40))
plot(g1)
# Change titles
g1 + labs(title="Plot of mileage vs acceleration",
subtitle = "Auto data",
x = "Acceleration",
y = "MPG",
caption = "ISLR dataset")
# Change marker size and color
g2 <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point(col="purple", size=3) +
geom_smooth(method="lm", col="darkgreen",linewidth=2) +
coord_cartesian(xlim=c(10,25),ylim=c(10,40)) +
labs(title="Plot of mileage vs acceleration",
subtitle = "Auto data",
x = "Acceleration",
y = "MPG",
caption = "ISLR dataset")
plot(g2)
# Change color gradient
g3 <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point(aes(col=year), size=3) +
geom_smooth(method="lm", col="darkgreen",size=2) +
coord_cartesian(xlim=c(10,25),ylim=c(10,40)) +
labs(title="Plot of mileage vs acceleration",
subtitle = "Auto data",
x = "Acceleration",
y = "MPG",
caption = "ISLR dataset")
g3 + scale_color_gradient(low="green",high="red")
# Change axis tick density and labels
g3 + scale_x_continuous(breaks = seq(10,25,3),
labels = function(x){paste0(x, 'm/s^2')})
# Change plot theme
g3 + theme_bw() + labs(subtitle="BW theme")
# Different regression model
g4 <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point(aes(col=year), size=3) +
geom_smooth(method="loess", col="magenta", se=F) +
coord_cartesian(xlim=c(10,25),ylim=c(10,40)) +
labs(title="Plot of mileage vs acceleration",
subtitle = "Auto data",
x = "Acceleration",
y = "MPG",
caption = "ISLR dataset")
plot(g4)
# Change axis tick density and labels
g3 + scale_x_continuous(breaks = seq(10,25,3),
labels = function(x){paste0(x, 'm/s^2')})
# Change plot theme
g3 + theme_bw() + labs(subtitle="BW theme")
g3 <- ggplot(Auto, aes(x=acceleration, y=mpg)) +
geom_point(aes(col=year), size=3) +
geom_smooth(method="lm", col="darkgreen",size=2) +
coord_cartesian(xlim=c(10,25),ylim=c(10,40)) +
labs(title="Plot of mileage vs acceleration",
subtitle = "Auto data",
x = "Acceleration",
y = "MPG",
caption = "ISLR dataset")
g3 + scale_color_gradient(low="green",high="red")
g5 <- ggplot(Auto, aes(mpg))
g5
g5 + geom_density()
g5 + geom_density(fill = "red")
g5 + geom_density(aes(fill=factor(cylinders)), alpha=.7)
g5 + geom_density(aes(fill=factor(year)), alpha=.7)
# Extract car brand names
splitNames <- strsplit(as.character(Auto$name),
split=" ")
splitNames
b <- c()
for(i in 1:length(splitNames)){
b <- c(b,splitNames[[i]][1])
}
Auto$brand <- factor(b)
# Calculate deviations from the mean
uniqueAuto <- Auto[!duplicated(Auto$brand),]
meanMPG <- mean(uniqueAuto$mpg)
uniqueAuto$mpg_dev <- uniqueAuto$mpg -meanMPG
uniqueAuto$mpg_type <- ifelse(uniqueAuto$mpg_dev <0,
"below",
"above")
uniqueAuto <- uniqueAuto[order(uniqueAuto$mpg_dev),]
uniqueAuto$brand <- factor(uniqueAuto$brand,
levels = uniqueAuto$brand)
# Deviation bar plot
ggplot(uniqueAuto, aes(x=brand, y=mpg_dev, labels=mpg_dev)) +
geom_bar(stat="identity", aes(fill=mpg_type),width=0.5) +
scale_fill_manual(name="Mileage",
labels=c("Above Average", "Below Average"),
values = c("above"="hotpink","below"="turquoise"))+
coord_flip()
# Deviation bar plot
ggplot(uniqueAuto, aes(x=brand, y=mpg_dev, labels=mpg_dev)) +
geom_bar( aes(fill=mpg_type),width=0.5) +
scale_fill_manual(name="Mileage",
labels=c("Above Average", "Below Average"),
values = c("above"="hotpink","below"="turquoise"))+
coord_flip()
# Deviation bar plot
ggplot(uniqueAuto, aes(x=brand, y=mpg_dev, labels=mpg_dev)) +
geom_bar( aes(fill=mpg_type),width=0.5) +
scale_fill_manual(name="Mileage",
labels=c("Above Average", "Below Average"),
values = c("above"="hotpink","below"="turquoise"))+
coord_flip()
# Deviation bar plot
ggplot(uniqueAuto, aes(x=brand, y=mpg_dev, labels=mpg_dev)) +
geom_bar(stat="identity", aes(fill=mpg_type),width=0.5) +
scale_fill_manual(name="Mileage",
labels=c("Above Average", "Below Average"),
values = c("above"="hotpink","below"="turquoise"))+
coord_flip()
library(openxlsx)
myiris <- read.xlsx(xlsxFile = "iris2_dataset.xlsx")
library(openxlsx)
library(openxlsx)
myiris <- read.xlsx(xlsxFile = "iris2_dataset.xlsx")
library(openxlsx)
myiris <- read.xlsx(xlsxFile = "iris2_dataset.xlsx")
rm(list = ls()) # cleaning the workspace
library(openxlsx)
myiris <- read.xlsx(xlsxFile = "iris2_dataset.xlsx")
str(myiris)
head(myiris)
myiris_cols <- read.xlsx(xlsxFile = "iris2_dataset.xlsx", colNames = F) # wrong way: no column names
str(myiris_cols)
myiris <- read.xlsx(xlsxFile = "iris2_dataset.xlsx")
iris2_dataset.xlsx
myiris <- read.xlsx(xlsxFile = "iris2_dataset.xlsx")
myiris <- read.xlsx(xlsxFile = "iris2_dataset.xlsx")
## From Excel sheet ==========================================================
install.packages("openxlsx")  # Install the package
library(openxlsx)             # Load the package
library(openxlsx)
myiris <- read.xlsx(xlsxFile = "iris2_dataset.xlsx")
myiris <- read.xlsx(xlsxFile = "C:\Users\nafmu\Desktop\Cognitive Tech\R\Lecture 3 R for data analysis-20241203/iris2_dataset.xlsx")
myiris <- read.xlsx(xlsxFile = "C:/Users/nafmu/Desktop/Cognitive Tech/R/Lecture 3 R for data analysis-20241203/iris2_dataset.xlsx")
str(myiris)
head(myiris)
myiris_cols <- read.xlsx(xlsxFile = "iris2_dataset.xlsx", colNames = F) # wrong way: no column names
myiris_cols <- read.xlsx(myiris, colNames = F) # wrong way: no column names xlsxFile = "iris2_dataset.xlsx"
myiris_cols <- read.xlsx(myiris, colNames = F) # wrong way: no column names xlsxFile = "iris2_dataset.xlsx"
myiris_cols <- read.xlsx(xlsxFile = "C:/Users/nafmu/Desktop/Cognitive Tech/R/Lecture 3 R for data analysis-20241203/iris2_dataset.xlsx", colNames = F) # wrong way: no column names
str(myiris_cols)
head(myiris_cols)
myiris_row <- read.xlsx(xlsxFile = "iris2_dataset.xlsx", rowNames = T) # wrong way: first values as row names
myiris3 <- read.xlsx(xlsxFile = "iris2_dataset.xlsx", startRow = 3, colNames = F) # starting from the 3rd row
str(myiris3)
myiris3 <- read.xlsx(xlsxFile = "C:/Users/nafmu/Desktop/Cognitive Tech/R/Lecture 3 R for data analysis-20241203/iris2_dataset.xlsx", startRow = 3, colNames = F) # starting from the 3rd row
str(myiris3)
head(myiris3)
nci <- read.csv(file = "NCI.csv", header = T)
str(nci)
x <- seq(-3,3,0.01)
f <- dnorm(x) # probability density function
plot(x,f,pch=19)
# Illustration of cumulative distribution function
segments(x0 = seq(-3,-1.64,0.001), y0=0,
x1=,seq(-3,-1.64,0.001), y1=dnorm(seq(-3,-1.64,0.001)),
col="red",lwd=4)
pnorm(-1.64) # cumulative distribution function
qnorm(0.05) # inverse cumulative distribution function
pts <- rnorm(10000) # random generator from standard normal distribution
hist(pts,50,add=T,col=rgb(0,0,1, alpha=0.5), freq = F)
## Statistical testing ====================================================
library(ISLR)
data(Auto)
attach(Auto)
# Download the fish dataset from the Educational Platform and load it.
read.csv(fish.csv, header = TRUE, sep = ",", dec = ".")
# Download the fish dataset from the Educational Platform and load it.
read.csv(filename="fish.csv", header = TRUE, sep = ",", dec = ".")
# Download the fish dataset from the Educational Platform and load it.
read.table(file = "fish.csv", header = T, sep = ',')
# Download the fish dataset from the Educational Platform and load it.
data = "C:/Users/nafmu/Desktop/Cognitive Tech/R/Lab. 3 R for data analysis-20241203/fish.csv"
read.table(file = data, header = T, sep = ',')
# a) Check the class of the object in which the data are stored.
class(data)
a=read.table(file = data, header = T, sep = ',')
# a) Check the class of the object in which the data are stored.
class(a)
data <- "C:/Users/nafmu/Desktop/Cognitive Tech/R/Lab. 3 R for data analysis-20241203/fish.csv"
loaded_data <- read.table(file = data, header = T, sep = ',')
# a) Check the class of the object in which the data are stored.
class(data)
class(loaded_data)
str(data)
str(loaded_data)
# c) Use the table function to check how many different fish you have in your data.
read.table(file=loaded_data, header = TRUE, sep = ",")
# c) Use the table function to check how many different fish you have in your data.
read.table(loaded_data, header = TRUE, sep = ",")
# c) Use the table function to check how many different fish you have in your data.
read.table(loaded_data, header = TRUE, sep = ",")
read.table(data, header = TRUE, sep = ",")
# d) Summarize all variables by calculating their basic statistics.
summary(data)
# d) Summarize all variables by calculating their basic statistics.
summary(loaded_data)
# e) For each variable, check how many missing values there are in your data.
#
# weight 4
# length1 2
# length2 1
# length 1
# length 3
# height 2
# width none
is_missing <- is.na(loaded_data)
head(is_missing)
table(is_missing)
complete_data <- complete.cases(loaded_data)
is_missing <- is.na(complete_data)
is_missing <- is.na(complete_data)
head(is_missing)
table(is_missing)
complete_data <- complete.cases(loaded_data)
missing_data <- is.na(complete_data)
head(missing_data)
table(missing_data)
any(missing_data) # is any record missing?
all(missing_data) # are all records missing?
head(missing_data)
table(missing_data)
apply(myiris, 2, function(i) {table(is.na(i))})
complete_data
complete_data <- complete.cases(loaded_data)
missing_data <- is.na(complete_data)
any(missing_data) # is any record missing?
all(missing_data) # are all records missing?
head(missing_data)
table(missing_data)
apply(myiris, 2, function(i) {table(is.na(i))})
str(loaded_data)
table(data$Species)
table(data$species)
read.table(data, header = TRUE, sep = ",")
table(loaded_data$Species)
# e) For each variable, check how many missing values there are in your data.
#
# weight 4
# length1 2
# length2 1
# length 1
# length 3
# height 2
# width none
is_missing <- is.na(loaded_data)
head(is_missing)
table(is_missing) #total missing values are 11
complete_data <- complete.cases(loaded_data)
complete_data
missing_data <- is.na(complete_data)
any(missing_data) # is any record missing?
# e) For each variable, check how many missing values there are in your data.
#
# weight 4
# length1 2
# length2 1
# length 1
# length 3
# height 2
# width none
is_missing <- is.na(loaded_data)
head(is_missing)
table(is_missing) #total missing values are 11
complete_data <- complete.cases(loaded_data)
complete_data
# e) For each variable, check how many missing values there are in your data.
#
# weight 4
# length1 2
# length2 1
# length 1
# length 3
# height 2
# width none
is_missing <- is.na(loaded_data)
head(is_missing)
table(is_missing) #total missing values are 11
apply(loaded_data, 2, function(i) {table(is.na(i))})
unlist(apply(loaded_data, 2, function(i) {table(is.na(i))}))
apply(loaded_data, 2, function(i) {table(is.na(i))})
New_complete_data <- loaded_data[complete_data,] # removing rows with missing values
New_complete_data
complete_data
any_missing <- is.na(New_complete_data)
head(any_missing)
apply(New_complete_data, 2, function(i) {table(is.na(i))})
write.csv(New_complete_data, file = 'New_complete_data.csv')
write.csv(New_complete_data, file = 'New_complete_data.csv')
my_heart <- read.table(file = heart, header = T, sep = ',')
# TASK 2
# Download the Heart dataset from the Educational Platform and load the data (you may use
# the read.csv function suitable for comma-separated files).
heart = "C:/Users/nafmu/Desktop/Cognitive Tech/R/Lab. 3 R for data analysis-20241203/Heart.csv"
my_heart <- read.table(file = heart, header = T, sep = ',')
my_heart
## Statistical testing ====================================================
library(ISLR)
data(Auto)
attach(Auto)
sAuto <- subset(Auto, cylinders >=6)
# t-test
tt <- t.test(horsepower~cylinders, data=sAuto)
tt$statistic
tt$p.value # There is a significant difference in horsepower between cars with 6 and 8 cylinders
sAuto
my_heart
# a) Using t-tests, check whether there are statistically significant differences in:
#   • Cholesterol levels (Chol) in different Fasting Blood Sugar groups (Fbs: 0 - normal, 1 elevated);
# t-test
chol_levels <- t.test(Chol~Fbs, data=my_heart)
chol_levels$statistic
chol_levels$p.value
# • Maximum Heart Rates (MaxHR) in people with and without Heart Disease (AHD);
Heart_RATE <- t.test(MaxHR~Fbs, data=my_heart)
Heart_RATE$statistic
Heart_RATE$p.value
my_heart
# • Resting Blood Pressure (RestBP) depending on Sex (0 - female, 1 – male).
BP_Sex <- t.test(RestBP~Sex, data=my_heart)
BP_Sex$statistic
BP_Sex$p.value
# b) Verify the results of the t-tests with boxplots.
boxplot(Chol~Fbs, data=my_heart)
boxplot(MaxHR~Fbs, data=my_heart)
boxplot(RestBP~Sex, data=my_heart)
# Contingency table
teaTesting <- matrix(c(3,1,1,3), nrow = 2,
dimnames = list(Guess=c("Milk","Tea"),Truth=c("Milk","Tea")))
teaTesting
Sex_ADH <- fisher.test(my_heart)
ft$p.value # The lady doesn't know her tea
Sex_ADH$p.value
Sex_ADH$estimate
Sex_ADH <- fisher.test(my_heart)
my_heart
my_heart[2]
Sex_ADH <- fisher.test(my_heart[3], my_heart[-1])
BP_Sex$p.value
# b) Verify the results of the t-tests with boxplots.
boxplot(Chol~Fbs, data=my_heart)
Sex_ADH <- fisher.test(my_heart[3,-1])
Sex_ADH$p.value
Sex_ADH$estimate
# c) Using Fisher tests, check if there is a statistically significant dependency between:
#   • Sex (0 - female, 1 – male) and people with and without Heart Disease (AHD);
#create table with sex and heart disease only
sex_adh_table = matrix(c(my_heart[3], c(my_heart[-1])))
sex_adh_table
my_heart[3]
my_heart[-1]
my_heart[15]
# c) Using Fisher tests, check if there is a statistically significant dependency between:
#   • Sex (0 - female, 1 – male) and people with and without Heart Disease (AHD);
#create table with sex and heart disease only
sex_adh_table = matrix(c(my_heart[3], c(my_heart[15])))
sex_adh_table
Sex_ADH <- fisher.test(sex_adh_table)
# c) Using Fisher tests, check if there is a statistically significant dependency between:
#   • Sex (0 - female, 1 – male) and people with and without Heart Disease (AHD);
#create table with sex and heart disease only
sex_adh_table = table(my_heart$sex, my_heart$ADH)
my_heart$ADH
my_heart$sex
# c) Using Fisher tests, check if there is a statistically significant dependency between:
#   • Sex (0 - female, 1 – male) and people with and without Heart Disease (AHD);
#create table with sex and heart disease only
sex_adh_table = table(my_heart$sex, my_heart$ADH)
Sex_ADH <- fisher.test(sex_adh_table)
my_heart
# c) Using Fisher tests, check if there is a statistically significant dependency between:
#   • Sex (0 - female, 1 – male) and people with and without Heart Disease (AHD);
#create table with sex and heart disease only
sex_adh_table = table(my_heart$Sex, my_heart$ADH)
# c) Using Fisher tests, check if there is a statistically significant dependency between:
#   • Sex (0 - female, 1 – male) and people with and without Heart Disease (AHD);
#create table with sex and heart disease only
sex_adh_table = table(my_heart$Sex, my_heart$ADH)
# c) Using Fisher tests, check if there is a statistically significant dependency between:
#   • Sex (0 - female, 1 – male) and people with and without Heart Disease (AHD);
#create table with sex and heart disease only
sex_adh_table = table(my_heart$Sex, my_heart$AHD)
Sex_AHD <- fisher.test(sex_adh_table)
Sex_AHD$p.value
Sex_AHD$estimate
sex_Cpain <- fisher.test(sex_Cpain_table)
sex_Cpain$p.value
sex_Cpain$estimate
# • Sex (0 - female, 1 – male) and Chest Pain type (ChestPain).
sex_Cpain_table = table(my_heart$Sex, my_heart$ChestPain)
sex_Cpain <- fisher.test(sex_Cpain_table)
sex_Cpain$p.value
sex_Cpain$estimate
#TASK 3
# a) Create a plot with probability density function for the standard normal distribution for x
# from -4 to 4.
x <- seq(-4,4,0.01)
f <- dnorm(x) # probability density function
plot(x,f,pch=19)
#TASK 3
# a) Create a plot with probability density function for the standard normal distribution for x
# from -4 to 4.
x <- seq(-4,4,0.06)
f <- dnorm(x) # probability density function
plot(x,f,pch=19)
#TASK 3
# a) Create a plot with probability density function for the standard normal distribution for x
# from -4 to 4.
x <- seq(-4,4,0.01)
f <- dnorm(x) # probability density function
plot(x,f,pch=19)
#TASK 3
# a) Create a plot with probability density function for the standard normal distribution for x
# from -4 to 4.
x <- seq(-4,4,0.01)
f <- dnorm(x) # probability density function
plot(x,f,pch=19)
